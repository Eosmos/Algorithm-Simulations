import{a as Rt}from"./chunk-ZW3SWSXV.js";import{A as N,B as wt,J as yt,L as Ot,O as V,R as it,S as kt,Z as Tt,c as bt,h as O,k as Ct,l as Pt,m as tt,p as L,q as D,r as et,t as Mt,u as nt,v as _t,z as A}from"./chunk-IMA2JTAA.js";import{k as Z,q as j,r as Et,s as vt,t as St}from"./chunk-SKIYKJGI.js";import{i as gt,k as ft,l as xt,n as ut}from"./chunk-7EKIJKTV.js";import{$a as $,Da as mt,Ia as q,Oa as f,Pa as pt,Qa as R,X as w,Xa as n,Y as y,Ya as e,Z as st,Za as x,_ as lt,_a as Y,ab as ht,db as M,gb as W,hb as Q,ib as U,kb as t,lb as K,nb as X,ra as ct,ta as dt,ua as d}from"./chunk-CS32D7W3.js";var Ht=["threeCanvas"],Lt=["attentionCanvas"],Nt=["posEncodingCanvas"];function Vt(p,i){p&1&&(Y(0),t(1,"\u25B6"),$())}function It(p,i){p&1&&(Y(0),t(1,"\u23F8"),$())}function Ft(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 1: Input Embedding"),e(),n(3,"p"),t(4,"The input tokens are converted into dense vector representations (embeddings) that capture semantic meaning. Each token is mapped to a fixed-size vector through a learned embedding matrix."),e()())}function Bt(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 2: Positional Encoding"),e(),n(3,"p"),t(4,"Since the self-attention mechanism is permutation invariant, information about token positions in the sequence is added through positional encodings, which are then combined with the embeddings."),e()())}function Gt(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 3: Multi-Head Self-Attention"),e(),n(3,"p"),t(4,"The encoder applies self-attention where each token can attend to all other tokens. Multiple attention heads learn different relationship patterns in parallel."),e()())}function qt(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 4: Feed-Forward Network"),e(),n(3,"p"),t(4,"Each position goes through a fully connected feed-forward network independently, applying the same set of weights to each token. This adds non-linearity and increases model capacity."),e()())}function Wt(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 5: Masked Self-Attention"),e(),n(3,"p"),t(4,"In the decoder, self-attention is masked to ensure that predictions for position i can only depend on known outputs at positions less than i, preventing information leakage."),e()())}function Qt(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 6: Encoder-Decoder Attention"),e(),n(3,"p"),t(4,"The decoder attends to the encoder outputs, allowing it to focus on relevant parts of the input sequence when generating each output token."),e()())}function Ut(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 7: Linear Layer"),e(),n(3,"p"),t(4,"The decoder output is projected through a linear layer to produce logits corresponding to the vocabulary size for each position."),e()())}function Kt(p,i){p&1&&(n(0,"div")(1,"h3"),t(2,"Step 8: Softmax"),e(),n(3,"p"),t(4,"The logits are converted to probability distributions over the vocabulary, and the highest probability tokens are selected for the output sequence."),e()())}function Jt(p,i){if(p&1&&(n(0,"div",94)(1,"h3",95),t(2),e(),n(3,"p",96),t(4),e(),n(5,"p",97),t(6),e(),n(7,"p",98),t(8),e(),n(9,"div",99)(10,"a",100),t(11,"View Paper"),e()()()),p&2){let a=i.$implicit;d(2),K(a.title),d(2),K(a.authors),d(2),X("",a.publication," (",a.year,")"),d(2),K(a.description),d(2),f("href",a.link,ct)}}var Dt=class p{threeCanvas;attentionCanvas;posEncodingCanvas;currentStep=0;isPlaying=!1;playInterval=null;totalSteps=8;autoPlaySpeed=3500;scene;camera;renderer;controls;animationFrameId;encoder=[];decoder=[];connectionLines=[];attentionSvg;posEncodingSvg;sampleSentence="The transformer model processes input sequences efficiently.";tokens=[];attentionWeights=[];activeSection="overview";researchPapers=[{title:"Attention Is All You Need",authors:"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., & Polosukhin, I.",year:2017,publication:"Advances in Neural Information Processing Systems (NIPS)",link:"https://arxiv.org/abs/1706.03762",description:"The seminal paper that introduced the Transformer architecture."},{title:"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",authors:"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K.",year:2018,publication:"Proceedings of NAACL-HLT 2019",link:"https://arxiv.org/abs/1810.04805",description:"Introduces BERT, a transformer-based model that revolutionized NLP."},{title:"Language Models are Few-Shot Learners",authors:"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ..., Amodei, D.",year:2020,publication:"Advances in Neural Information Processing Systems",link:"https://arxiv.org/abs/2005.14165",description:"Describes GPT-3, showing the capabilities of large-scale transformer models."},{title:"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",authors:"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ..., Houlsby, N.",year:2020,publication:"ICLR 2021",link:"https://arxiv.org/abs/2010.11929",description:"Introduces Vision Transformer (ViT), adapting the Transformer architecture for computer vision tasks."}];constructor(){this.tokens=this.sampleSentence.split(/\s+/),this.initializeAttentionWeights()}ngOnInit(){}ngAfterViewInit(){this.initThreeJs(),this.initAttentionVisualization(),this.initPositionalEncodingVisualization(),this.updateSimulation()}ngOnDestroy(){this.isPlaying&&this.stopAutoPlay(),this.animationFrameId&&cancelAnimationFrame(this.animationFrameId),this.scene&&this.scene.children.forEach(i=>{i instanceof D&&(i.geometry.dispose(),i.material instanceof Pt?i.material.dispose():Array.isArray(i.material)&&i.material.forEach(a=>a.dispose()))}),this.renderer&&this.renderer.dispose()}onWindowResize(){this.camera&&this.renderer&&this.threeCanvas&&(this.camera.aspect=this.threeCanvas.nativeElement.clientWidth/this.threeCanvas.nativeElement.clientHeight,this.camera.updateProjectionMatrix(),this.renderer.setSize(this.threeCanvas.nativeElement.clientWidth,this.threeCanvas.nativeElement.clientHeight)),this.updateAttentionVisualization(),this.updatePositionalEncodingVisualization()}initializeAttentionWeights(){let i=this.tokens.length;this.attentionWeights=[];for(let a=0;a<i;a++){let o=[],r=0;for(let s=0;s<i;s++){let l=Math.random();a===s&&(l*=2),Math.abs(a-s)<=2&&(l*=1.5),o.push(l),r+=l}for(let s=0;s<i;s++)o[s]=o[s]/r;this.attentionWeights.push(o)}}initThreeJs(){if(!this.threeCanvas)return;this.scene=new _t,this.scene.background=new Ct(791592);let i=this.threeCanvas.nativeElement.clientWidth,a=this.threeCanvas.nativeElement.clientHeight;this.camera=new Mt(75,i/a,.1,1e3),this.camera.position.set(0,8,20),this.renderer=new Tt({canvas:this.threeCanvas.nativeElement,antialias:!0}),this.renderer.setSize(i,a),this.renderer.setPixelRatio(window.devicePixelRatio),this.controls=new Rt(this.camera,this.renderer.domElement),this.controls.enableDamping=!0,this.controls.dampingFactor=.05,this.controls.minDistance=10,this.controls.maxDistance=50;let o=new kt(4210752,2);this.scene.add(o);let r=new it(16777215,1.5);r.position.set(1,2,1),this.scene.add(r);let s=new it(16777215,.5);s.position.set(-1,-1,-1),this.scene.add(s),this.createTransformerArchitecture(),this.animate()}animate(){this.animationFrameId=requestAnimationFrame(()=>this.animate()),this.controls&&this.controls.update(),this.renderer&&this.scene&&this.camera&&this.renderer.render(this.scene,this.camera)}createTransformerArchitecture(){if(!this.scene)return;let i=6,a=1.5,o=3,r=.6,s=.5,l=this.createBlock(o,r,s,6600182,.9);l.position.set(-6,-2,0),this.scene.add(l);let E=this.createBlock(o,r,s,6600182,.9);E.position.set(6,-2,0),this.scene.add(E);let v=this.createBlock(o,r,s,16751941,.9);v.position.set(-6,-1,0),this.scene.add(v);let S=this.createBlock(o,r,s,16751941,.9);S.position.set(6,-1,0),this.scene.add(S);let b=this.createBlock(o,r,s,2405502,.9);b.position.set(6,i*a+1,0),this.scene.add(b);let k=this.createBlock(o,r,s,2405502,.9);k.position.set(6,i*a+2,0),this.scene.add(k),this.addTextLabel("Input Embeddings",-6,-2,1),this.addTextLabel("Positional Encoding",-6,-1,1),this.addTextLabel("Output Embeddings",6,-2,1),this.addTextLabel("Positional Encoding",6,-1,1),this.addTextLabel("Linear",6,i*a+1,1),this.addTextLabel("Softmax",6,i*a+2,1);for(let g=0;g<i;g++){let u=new nt,I=this.createBlock(o,r,s,4359668,.9);I.position.y=1,u.add(I);let F=this.createBlock(o,r,s,8146431,.9);F.position.y=0,u.add(F);let B=this.createNormIndicator();B.position.set(1.8,1,0),u.add(B);let G=this.createNormIndicator();G.position.set(1.8,0,0),u.add(G),u.position.set(-6,g*a+1,0),this.scene.add(u),this.encoder.push(u),g===0&&(this.addTextLabel("Multi-Head Self-Attention",-6,g*a+2,1),this.addTextLabel("Feed Forward Network",-6,g*a+1,1))}for(let g=0;g<i;g++){let u=new nt,I=this.createBlock(o,r,s,51711,.9);I.position.y=2,u.add(I);let F=this.createBlock(o,r,s,16751941,.9);F.position.y=1,u.add(F);let B=this.createBlock(o,r,s,8146431,.9);B.position.y=0,u.add(B);let G=this.createNormIndicator();G.position.set(1.8,2,0),u.add(G);let ot=this.createNormIndicator();ot.position.set(1.8,1,0),u.add(ot);let at=this.createNormIndicator();at.position.set(1.8,0,0),u.add(at),u.position.set(6,g*a+1,0),this.scene.add(u),this.decoder.push(u),g===0&&(this.addTextLabel("Masked Self-Attention",6,g*a+3,1),this.addTextLabel("Encoder-Decoder Attention",6,g*a+2,1),this.addTextLabel("Feed Forward Network",6,g*a+1,1));let At=new A({color:9155834,opacity:.4,transparent:!0}),J=[];J.push(new O(-4.5,g*a+1.5,0)),J.push(new O(4.5,g*a+1.5,0));let zt=new L().setFromPoints(J),rt=new N(zt,At);this.scene.add(rt),this.connectionLines.push(rt)}this.addVerticalConnections(-6,0,i,a,9155834),this.addVerticalConnections(6,0,i,a,9155834);let _=[];_.push(new O(-6,-1,0)),_.push(new O(-6,0,0));let P=new L().setFromPoints(_),z=new N(P,new A({color:9155834,opacity:.4,transparent:!0}));this.scene.add(z);let H=[];H.push(new O(6,-1,0)),H.push(new O(6,0,0));let h=new L().setFromPoints(H),c=new N(h,new A({color:9155834,opacity:.4,transparent:!0}));this.scene.add(c);let m=[];m.push(new O(6,i*a,0)),m.push(new O(6,i*a+1,0));let C=new L().setFromPoints(m),T=new N(C,new A({color:9155834,opacity:.4,transparent:!0}));this.scene.add(T),this.addTextLabel("Encoder",-9,i*a/2,0),this.addTextLabel("Decoder",9,i*a/2,0),this.addTextLabel("Nx",-7.5,i*a/2,0),this.addTextLabel("Nx",7.5,i*a/2,0)}addTextLabel(i,a,o,r){if(!this.scene)return;let s=new D(new Ot(.05,8,8),new tt({color:16777215}));s.position.set(a,o,r),this.scene.add(s)}addVerticalConnections(i,a,o,r,s){if(!this.scene)return;let l=new A({color:s,opacity:.4,transparent:!0});for(let E=0;E<o-1;E++){let v=[];v.push(new O(i,a+E*r+1,0)),v.push(new O(i,a+(E+1)*r,0));let S=new L().setFromPoints(v),b=new N(S,l);this.scene.add(b)}}createBlock(i,a,o,r,s){let l=new et(i,a,o),E=new V({color:r,opacity:s,transparent:!0,side:bt,specular:1118481,shininess:30}),v=new D(l,E),S=new yt(l),b=new wt(S,new A({color:0,opacity:.2,transparent:!0}));return v.add(b),v}createNormIndicator(){let i=new et(.1,.1,.1),a=new tt({color:2405502});return new D(i,a)}initAttentionVisualization(){this.attentionCanvas&&(this.attentionSvg=Z(this.attentionCanvas.nativeElement).append("svg").attr("width","100%").attr("height","100%"),this.updateAttentionVisualization())}updateAttentionVisualization(){if(!this.attentionSvg||!this.attentionCanvas)return;let i=Math.max(this.attentionCanvas.nativeElement.clientWidth,400),a=Math.max(this.attentionCanvas.nativeElement.clientHeight,400),o=50;this.attentionSvg.selectAll("*").remove();let r=this.tokens.length,s=Math.max(Math.min((i-o*2)/r,(a-o*2)/r),20);this.attentionSvg.attr("width",i).attr("height",a),this.attentionSvg.append("text").attr("x",i/2).attr("y",20).attr("text-anchor","middle").attr("fill","#ffffff").style("font-size","16px").style("font-weight","bold").text("Self-Attention Weights");let l=j().domain(this.tokens.map((h,c)=>c.toString())).range([o,o+s*r]).padding(.05),E=j().domain(this.tokens.map((h,c)=>c.toString())).range([o,o+s*r]).padding(.05),v=vt(St).domain([0,1]),S=this.attentionSvg.append("g");for(let h=0;h<r;h++)for(let c=0;c<r;c++){let m=l(h.toString()),C=E(c.toString()),T=l.bandwidth(),g=E.bandwidth();m!==void 0&&C!==void 0&&T>0&&g>0&&(S.append("rect").attr("x",m).attr("y",C).attr("width",T).attr("height",g).attr("fill",v(this.attentionWeights[h][c])).attr("stroke","#162a4a").attr("stroke-width",1).attr("rx",2).attr("ry",2).on("mouseover",u=>{this.attentionSvg.append("text").attr("class","tooltip").attr("x",u.offsetX+10).attr("y",u.offsetY-10).attr("fill","#e1e7f5").text(`${this.tokens[h]} \u2192 ${this.tokens[c]}: ${this.attentionWeights[h][c].toFixed(2)}`)}).on("mouseout",()=>{this.attentionSvg.selectAll(".tooltip").remove()}),this.attentionWeights[h][c]>.3&&S.append("text").attr("x",m+T/2).attr("y",C+g/2).attr("text-anchor","middle").attr("dominant-baseline","middle").attr("fill",this.attentionWeights[h][c]>.5?"#ffffff":"#000000").style("font-size","10px").text(this.attentionWeights[h][c].toFixed(2)))}this.attentionSvg.selectAll(".x-label").data(this.tokens).enter().append("text").attr("class","x-label").attr("x",(h,c)=>{let m=l(c.toString());return m!==void 0?m+l.bandwidth()/2:0}).attr("y",o-10).attr("text-anchor","middle").attr("fill","#e1e7f5").style("font-size","12px").text(h=>h),this.attentionSvg.selectAll(".y-label").data(this.tokens).enter().append("text").attr("class","y-label").attr("x",o-10).attr("y",(h,c)=>{let m=E(c.toString());return m!==void 0?m+E.bandwidth()/2:0}).attr("text-anchor","end").attr("dominant-baseline","middle").attr("fill","#e1e7f5").style("font-size","12px").text(h=>h);let b=Math.min(250,i-40),k=20,_=Math.max(i-b-20,o),P=a-40,H=this.attentionSvg.append("defs").append("linearGradient").attr("id","attention-gradient").attr("x1","0%").attr("y1","0%").attr("x2","100%").attr("y2","0%");H.append("stop").attr("offset","0%").attr("stop-color",v(0)),H.append("stop").attr("offset","100%").attr("stop-color",v(1)),this.attentionSvg.append("rect").attr("x",_).attr("y",P).attr("width",b).attr("height",k).style("fill","url(#attention-gradient)"),this.attentionSvg.append("text").attr("x",_).attr("y",P-5).attr("text-anchor","start").attr("fill","#e1e7f5").style("font-size","10px").text("0.0"),this.attentionSvg.append("text").attr("x",_+b).attr("y",P-5).attr("text-anchor","end").attr("fill","#e1e7f5").style("font-size","10px").text("1.0"),this.attentionSvg.append("text").attr("x",_+b/2).attr("y",P-5).attr("text-anchor","middle").attr("fill","#e1e7f5").style("font-size","10px").text("Attention Weight")}initPositionalEncodingVisualization(){this.posEncodingCanvas&&(this.posEncodingSvg=Z(this.posEncodingCanvas.nativeElement).append("svg").attr("width","100%").attr("height","100%"),this.updatePositionalEncodingVisualization())}updatePositionalEncodingVisualization(){if(!this.posEncodingSvg||!this.posEncodingCanvas)return;let i=Math.max(this.posEncodingCanvas.nativeElement.clientWidth,400),a=Math.max(this.posEncodingCanvas.nativeElement.clientHeight,400),o=50;this.posEncodingSvg.selectAll("*").remove(),this.posEncodingSvg.attr("width",i).attr("height",a),this.posEncodingSvg.append("text").attr("x",i/2).attr("y",20).attr("text-anchor","middle").attr("fill","#ffffff").style("font-size","16px").style("font-weight","bold").text("Positional Encoding Vectors");let r=10,s=20,l=[];for(let c=0;c<r;c++){let m=[];for(let C=0;C<s;C++){let T=C%2===0?Math.sin(c/Math.pow(1e4,C/s)):Math.cos(c/Math.pow(1e4,(C-1)/s));m.push(T)}l.push(m)}let E=Math.max((i-o*2)/s,10),v=Math.max((a-o*2)/r,10),S=Et().domain([-1,0,1]).range(["#ff6b6b","#162a4a","#24b47e"]),b=this.posEncodingSvg.append("g");for(let c=0;c<r;c++)for(let m=0;m<s;m++){let C=o+m*E,T=o+c*v;b.append("rect").attr("x",C).attr("y",T).attr("width",E).attr("height",v).attr("fill",S(l[c][m])).attr("stroke","#162a4a").attr("stroke-width",1).attr("rx",2).attr("ry",2).on("mouseover",g=>{this.posEncodingSvg.append("text").attr("class","tooltip").attr("x",g.offsetX+10).attr("y",g.offsetY-10).attr("fill","#e1e7f5").text(`Position ${c}, Dimension ${m}: ${l[c][m].toFixed(3)}`)}).on("mouseout",()=>{this.posEncodingSvg.selectAll(".tooltip").remove()})}this.posEncodingSvg.selectAll(".pos-label").data(Array.from({length:r},(c,m)=>m)).enter().append("text").attr("class","pos-label").attr("x",o-10).attr("y",c=>o+c*v+v/2).attr("text-anchor","end").attr("dominant-baseline","middle").attr("fill","#e1e7f5").style("font-size","12px").text(c=>`Pos ${c}`),this.posEncodingSvg.selectAll(".dim-label").data(Array.from({length:s},(c,m)=>m)).enter().append("text").attr("class","dim-label").attr("x",c=>o+c*E+E/2).attr("y",o-10).attr("text-anchor","middle").attr("fill","#e1e7f5").style("font-size","10px").text(c=>`${c}`);let k=Math.min(250,i-40),_=20,P=Math.max(i-k-20,o),z=a-40,h=this.posEncodingSvg.append("defs").append("linearGradient").attr("id","pos-encoding-gradient").attr("x1","0%").attr("y1","0%").attr("x2","100%").attr("y2","0%");h.append("stop").attr("offset","0%").attr("stop-color",S(-1)),h.append("stop").attr("offset","50%").attr("stop-color",S(0)),h.append("stop").attr("offset","100%").attr("stop-color",S(1)),this.posEncodingSvg.append("rect").attr("x",P).attr("y",z).attr("width",k).attr("height",_).style("fill","url(#pos-encoding-gradient)"),this.posEncodingSvg.append("text").attr("x",P).attr("y",z-5).attr("text-anchor","start").attr("fill","#e1e7f5").style("font-size","10px").text("-1.0"),this.posEncodingSvg.append("text").attr("x",P+k/2).attr("y",z-5).attr("text-anchor","middle").attr("fill","#e1e7f5").style("font-size","10px").text("0.0"),this.posEncodingSvg.append("text").attr("x",P+k).attr("y",z-5).attr("text-anchor","end").attr("fill","#e1e7f5").style("font-size","10px").text("1.0"),this.posEncodingSvg.append("text").attr("x",P+k/2).attr("y",z+_+15).attr("text-anchor","middle").attr("fill","#e1e7f5").style("font-size","10px").text("Positional Encoding Value")}updateSimulation(){switch(this.resetComponentColors(),this.currentStep){case 0:this.highlightComponent(-6,-2,0,6600182,1.5);break;case 1:this.highlightComponent(-6,-1,0,16751941,1.5);break;case 2:this.highlightEncoderComponent(0,1,4359668,1.5);break;case 3:this.highlightEncoderComponent(0,0,8146431,1.5);break;case 4:this.highlightDecoderComponent(0,2,51711,1.5);break;case 5:this.highlightDecoderComponent(0,1,16751941,1.5),this.highlightConnectionLine(0);break;case 6:this.highlightComponent(6,6*1.5+1,0,2405502,1.5);break;case 7:this.highlightComponent(6,6*1.5+2,0,2405502,1.5);break;default:break}}resetComponentColors(){this.scene&&(this.scene.traverse(i=>{i instanceof D&&i.material instanceof V&&(i.material.emissive.set(0),i.material.emissiveIntensity=0)}),this.connectionLines&&this.connectionLines.length>0&&this.connectionLines.forEach(i=>{i.material instanceof A&&(i.material.color.set(9155834),i.material.opacity=.4)}))}highlightComponent(i,a,o,r,s){this.scene&&this.scene.traverse(l=>{l instanceof D&&Math.abs(l.position.x-i)<.1&&Math.abs(l.position.y-a)<.1&&Math.abs(l.position.z-o)<.1&&l.material instanceof V&&(l.material.emissive.set(r),l.material.emissiveIntensity=s)})}highlightEncoderComponent(i,a,o,r){if(!this.encoder||!this.encoder[i])return;this.encoder[i].traverse(l=>{l instanceof D&&Math.abs(l.position.y-a)<.1&&l.material instanceof V&&(l.material.emissive.set(o),l.material.emissiveIntensity=r)})}highlightDecoderComponent(i,a,o,r){if(!this.decoder||!this.decoder[i])return;this.decoder[i].traverse(l=>{l instanceof D&&Math.abs(l.position.y-a)<.1&&l.material instanceof V&&(l.material.emissive.set(o),l.material.emissiveIntensity=r)})}highlightConnectionLine(i){if(!this.connectionLines||i<0||i>=this.connectionLines.length)return;let a=this.connectionLines[i];a&&a.material instanceof A&&(a.material.color.set(16751941),a.material.opacity=1)}startAutoPlay(){this.isPlaying||(this.isPlaying=!0,this.playInterval=setInterval(()=>{this.nextStep()},this.autoPlaySpeed))}stopAutoPlay(){this.isPlaying&&(this.isPlaying=!1,this.playInterval&&(clearInterval(this.playInterval),this.playInterval=null))}togglePlay(){this.isPlaying?this.stopAutoPlay():this.startAutoPlay()}resetSimulation(){this.stopAutoPlay(),this.currentStep=0,this.updateSimulation()}nextStep(){this.currentStep<this.totalSteps-1?this.currentStep++:this.currentStep=0,this.updateSimulation()}prevStep(){this.currentStep>0?this.currentStep--:this.currentStep=this.totalSteps-1,this.updateSimulation()}goToStep(i){i>=0&&i<this.totalSteps&&(this.currentStep=i,this.updateSimulation())}showSection(i){this.activeSection=i}static \u0275fac=function(a){return new(a||p)};static \u0275cmp=mt({type:p,selectors:[["app-transformer-network"]],viewQuery:function(a,o){if(a&1&&(W(Ht,7),W(Lt,7),W(Nt,7)),a&2){let r;Q(r=U())&&(o.threeCanvas=r.first),Q(r=U())&&(o.attentionCanvas=r.first),Q(r=U())&&(o.posEncodingCanvas=r.first)}},hostBindings:function(a,o){a&1&&M("resize",function(){return o.onWindowResize()},!1,dt)},decls:587,vars:39,consts:[["threeCanvas",""],["attentionCanvas",""],["posEncodingCanvas",""],[1,"transformer-container"],[1,"sidebar"],[1,"logo"],[1,"nav-list"],[3,"click"],[1,"icon"],[1,"text"],[1,"sim-controls"],[1,"control-buttons"],["title","Reset",1,"btn",3,"click"],["title","Previous Step",1,"btn",3,"click"],["title","Play/Pause",1,"btn","play-btn",3,"click"],[1,"icon",3,"ngSwitch"],[4,"ngSwitchCase"],["title","Next Step",1,"btn",3,"click"],[1,"step-indicator"],[1,"step-progress"],[1,"progress-bar"],[1,"step-text"],[1,"content-area"],[1,"visualization-area"],[1,"three-canvas"],[1,"step-description"],[1,"step-content",3,"ngSwitch"],[1,"info-section",3,"hidden"],[1,"info-content"],[1,"application-cards"],[1,"app-card"],[1,"app-icon"],[1,"benefits-list"],[1,"architecture-diagram"],["width","800","height","500","viewBox","0 0 800 500","xmlns","http://www.w3.org/2000/svg"],["transform","translate(100, 50)"],["x","0","y","0","width","200","height","400","rx","8","fill","#162a4a","stroke","#4285f4","stroke-width","2"],["x","100","y","-20","text-anchor","middle","fill","#ffffff","font-size","18"],["x","20","y","30","width","160","height","70","rx","5","fill","#1e3a66","stroke","#8bb4fa","stroke-width","1"],["x","100","y","55","text-anchor","middle","fill","#ffffff","font-size","14"],["x","100","y","75","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","110","width","160","height","50","rx","5","fill","#1e3a66","stroke","#7c4dff","stroke-width","1"],["x","100","y","140","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","180","width","160","height","70","rx","5","fill","#1e3a66","stroke","#8bb4fa","stroke-width","1"],["x","100","y","205","text-anchor","middle","fill","#ffffff","font-size","14"],["x","100","y","225","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","260","width","160","height","50","rx","5","fill","#1e3a66","stroke","#7c4dff","stroke-width","1"],["x","100","y","290","text-anchor","middle","fill","#ffffff","font-size","14"],["x","100","y","340","text-anchor","middle","fill","#ffffff","font-size","18"],["x","20","y","370","width","160","height","30","rx","5","fill","#1e3a66","stroke","#64b5f6","stroke-width","1"],["x","100","y","390","text-anchor","middle","fill","#ffffff","font-size","12"],["transform","translate(500, 50)"],["x","0","y","0","width","200","height","400","rx","8","fill","#162a4a","stroke","#00c9ff","stroke-width","2"],["x","20","y","30","width","160","height","50","rx","5","fill","#1e3a66","stroke","#00c9ff","stroke-width","1"],["x","100","y","60","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","90","width","160","height","50","rx","5","fill","#1e3a66","stroke","#ff9d45","stroke-width","1"],["x","100","y","120","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","150","width","160","height","50","rx","5","fill","#1e3a66","stroke","#7c4dff","stroke-width","1"],["x","100","y","180","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","210","width","160","height","50","rx","5","fill","#1e3a66","stroke","#00c9ff","stroke-width","1"],["x","100","y","240","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","270","width","160","height","50","rx","5","fill","#1e3a66","stroke","#ff9d45","stroke-width","1"],["x","100","y","300","text-anchor","middle","fill","#ffffff","font-size","14"],["transform","translate(500, 460)"],["x","20","y","0","width","160","height","30","rx","5","fill","#1e3a66","stroke","#24b47e","stroke-width","1"],["x","100","y","20","text-anchor","middle","fill","#ffffff","font-size","14"],["x","20","y","40","width","160","height","30","rx","5","fill","#1e3a66","stroke","#24b47e","stroke-width","1"],["stroke","#8bb4fa","stroke-width","2","stroke-dasharray","5,5","fill","none"],["d","M300,115 L500,115"],["d","M300,295 L500,295"],["d","M100,470 L100,550 L700,550 L700,470"],["fill","#e1e7f5","font-size","14"],["x","400","y","100","text-anchor","middle"],["x","400","y","280","text-anchor","middle"],["x","400","y","540","text-anchor","middle"],[1,"attention-container"],[1,"attention-text"],[1,"equation"],[1,"formula"],[1,"attention-vis-container"],[1,"positional-container"],[1,"positional-text"],[1,"positional-vis-container"],[1,"research-intro"],[1,"papers-container"],["class","paper-card",4,"ngFor","ngForOf"],[1,"citation-info"],[1,"citation-formats"],[1,"citation-format"],[1,"citation-text"],[1,"applications-grid"],[1,"application-block"],[1,"app-icon","large"],[1,"future-applications"],[1,"paper-card"],[1,"paper-title"],[1,"paper-authors"],[1,"paper-publication"],[1,"paper-description"],[1,"paper-link"],["target","_blank","rel","noopener noreferrer",3,"href"]],template:function(a,o){if(a&1){let r=ht();n(0,"div",3)(1,"div",4)(2,"div",5)(3,"h2"),t(4,"Transformer Network"),e(),n(5,"p"),t(6,"Interactive Simulation"),e()(),n(7,"ul",6)(8,"li",7),M("click",function(){return w(r),y(o.showSection("overview"))}),n(9,"span",8),t(10,"\u{1F4CB}"),e(),n(11,"span",9),t(12,"Overview"),e()(),n(13,"li",7),M("click",function(){return w(r),y(o.showSection("architecture"))}),n(14,"span",8),t(15,"\u{1F3D7}\uFE0F"),e(),n(16,"span",9),t(17,"Architecture"),e()(),n(18,"li",7),M("click",function(){return w(r),y(o.showSection("attention"))}),n(19,"span",8),t(20,"\u{1F441}\uFE0F"),e(),n(21,"span",9),t(22,"Self-Attention"),e()(),n(23,"li",7),M("click",function(){return w(r),y(o.showSection("positional"))}),n(24,"span",8),t(25,"\u{1F4CD}"),e(),n(26,"span",9),t(27,"Positional Encoding"),e()(),n(28,"li",7),M("click",function(){return w(r),y(o.showSection("research"))}),n(29,"span",8),t(30,"\u{1F4DA}"),e(),n(31,"span",9),t(32,"Research Papers"),e()(),n(33,"li",7),M("click",function(){return w(r),y(o.showSection("applications"))}),n(34,"span",8),t(35,"\u{1F6E0}\uFE0F"),e(),n(36,"span",9),t(37,"Applications"),e()()(),n(38,"div",10)(39,"h3"),t(40,"Simulation Controls"),e(),n(41,"div",11)(42,"button",12),M("click",function(){return w(r),y(o.resetSimulation())}),n(43,"span",8),t(44,"\u21BA"),e()(),n(45,"button",13),M("click",function(){return w(r),y(o.prevStep())}),n(46,"span",8),t(47,"\u25C0"),e()(),n(48,"button",14),M("click",function(){return w(r),y(o.togglePlay())}),n(49,"span",15),q(50,Vt,2,0,"ng-container",16)(51,It,2,0,"ng-container",16),e()(),n(52,"button",17),M("click",function(){return w(r),y(o.nextStep())}),n(53,"span",8),t(54,"\u25B6"),e()()(),n(55,"div",18)(56,"div",19),x(57,"div",20),e(),n(58,"div",21),t(59),e()()()(),n(60,"div",22)(61,"div",23),x(62,"canvas",24,0),n(64,"div",25)(65,"div",26),q(66,Ft,5,0,"div",16)(67,Bt,5,0,"div",16)(68,Gt,5,0,"div",16)(69,qt,5,0,"div",16)(70,Wt,5,0,"div",16)(71,Qt,5,0,"div",16)(72,Ut,5,0,"div",16)(73,Kt,5,0,"div",16),e()()(),n(74,"div",27)(75,"h2"),t(76,"Transformer Networks: Overview"),e(),n(77,"div",28)(78,"h3"),t(79,"Purpose"),e(),n(80,"p"),t(81,"Transformer networks are a groundbreaking type of neural network architecture, introduced primarily for "),n(82,"strong"),t(83,"sequence-to-sequence tasks"),e(),t(84,", especially in "),n(85,"strong"),t(86,"Natural Language Processing (NLP)"),e(),t(87,". They were designed to overcome limitations of Recurrent Neural Networks (RNNs), particularly the difficulty in handling "),n(88,"strong"),t(89,"long-range dependencies"),e(),t(90," and the inherent "),n(91,"strong"),t(92,"sequential computation bottleneck"),e(),t(93," that prevents parallelization over the sequence length."),e(),n(94,"h3"),t(95,"Key Applications"),e(),n(96,"div",29)(97,"div",30)(98,"div",31),t(99,"\u{1F310}"),e(),n(100,"h4"),t(101,"Machine Translation"),e(),n(102,"p"),t(103,"Their original application, significantly improving translation quality."),e()(),n(104,"div",30)(105,"div",31),t(106,"\u{1F4DD}"),e(),n(107,"h4"),t(108,"Text Generation"),e(),n(109,"p"),t(110,"Powering models like GPT series that can generate coherent and contextually relevant text."),e()(),n(111,"div",30)(112,"div",31),t(113,"\u{1F50D}"),e(),n(114,"h4"),t(115,"Language Understanding"),e(),n(116,"p"),t(117,"Models like BERT excel at capturing contextual word meanings."),e()(),n(118,"div",30)(119,"div",31),t(120,"\u{1F5BC}\uFE0F"),e(),n(121,"h4"),t(122,"Computer Vision"),e(),n(123,"p"),t(124,"Vision Transformers (ViT) have adapted the architecture for image processing tasks."),e()()(),n(125,"h3"),t(126,"Core Innovation"),e(),n(127,"p"),t(128,"The core innovation is the "),n(129,"strong"),t(130,"self-attention mechanism"),e(),t(131,", which allows the model to weigh the importance of different parts of the input sequence when processing a specific part, regardless of their distance."),e(),n(132,"h3"),t(133,"Benefits Over RNNs"),e(),n(134,"ul",32)(135,"li")(136,"strong"),t(137,"Parallelization:"),e(),t(138," Allows training on longer sequences more efficiently"),e(),n(139,"li")(140,"strong"),t(141,"Long-range dependencies:"),e(),t(142," Direct connections between any positions with constant path length"),e(),n(143,"li")(144,"strong"),t(145,"Contextual understanding:"),e(),t(146," Better capture of relationships between tokens"),e(),n(147,"li")(148,"strong"),t(149,"Transfer learning:"),e(),t(150," Enables pre-training on large corpora and fine-tuning for specific tasks"),e()()()(),n(151,"div",27)(152,"h2"),t(153,"Transformer Architecture"),e(),n(154,"div",28)(155,"div",33),st(),n(156,"svg",34)(157,"g",35),x(158,"rect",36),n(159,"text",37),t(160,"Encoder"),e(),x(161,"rect",38),n(162,"text",39),t(163,"Multi-Head"),e(),n(164,"text",40),t(165,"Self-Attention"),e(),x(166,"rect",41),n(167,"text",42),t(168,"Feed Forward"),e(),x(169,"rect",43),n(170,"text",44),t(171,"Multi-Head"),e(),n(172,"text",45),t(173,"Self-Attention"),e(),x(174,"rect",46),n(175,"text",47),t(176,"Feed Forward"),e(),n(177,"text",48),t(178,"\xD7N"),e(),x(179,"rect",49),n(180,"text",50),t(181,"Input Embeddings + Position"),e()(),n(182,"g",51),x(183,"rect",52),n(184,"text",37),t(185,"Decoder"),e(),x(186,"rect",53),n(187,"text",54),t(188,"Masked Self-Attention"),e(),x(189,"rect",55),n(190,"text",56),t(191,"Encoder-Decoder Attention"),e(),x(192,"rect",57),n(193,"text",58),t(194,"Feed Forward"),e(),x(195,"rect",59),n(196,"text",60),t(197,"Masked Self-Attention"),e(),x(198,"rect",61),n(199,"text",62),t(200,"Encoder-Decoder Attention"),e(),n(201,"text",48),t(202,"\xD7N"),e(),x(203,"rect",49),n(204,"text",50),t(205,"Output Embeddings + Position"),e()(),n(206,"g",63),x(207,"rect",64),n(208,"text",65),t(209,"Linear"),e(),x(210,"rect",66),n(211,"text",54),t(212,"Softmax"),e()(),n(213,"g",67),x(214,"path",68)(215,"path",69)(216,"path",70),e(),n(217,"g",71)(218,"text",72),t(219,"Attention Weights"),e(),n(220,"text",73),t(221,"Attention Weights"),e(),n(222,"text",74),t(223,"Output Probabilities"),e()()()(),lt(),n(224,"h3"),t(225,"Encoder-Decoder Structure"),e(),n(226,"p"),t(227,"The original Transformer architecture follows an Encoder-Decoder structure designed for sequence-to-sequence tasks like translation."),e(),n(228,"h3"),t(229,"Encoder"),e(),n(230,"p"),t(231,"The encoder consists of a stack of identical layers, each with two sub-layers:"),e(),n(232,"ul")(233,"li")(234,"strong"),t(235,"Multi-Head Self-Attention:"),e(),t(236," Attends to positions in the input sequence"),e(),n(237,"li")(238,"strong"),t(239,"Position-wise Feed-Forward Network:"),e(),t(240," Applies non-linear transformations"),e()(),n(241,"p"),t(242,"Each sub-layer is wrapped with residual connections and layer normalization."),e(),n(243,"h3"),t(244,"Decoder"),e(),n(245,"p"),t(246,"The decoder also consists of a stack of identical layers, but with three sub-layers:"),e(),n(247,"ul")(248,"li")(249,"strong"),t(250,"Masked Multi-Head Self-Attention:"),e(),t(251," Prevents positions from attending to future positions"),e(),n(252,"li")(253,"strong"),t(254,"Multi-Head Encoder-Decoder Attention:"),e(),t(255," Attends to the encoder output"),e(),n(256,"li")(257,"strong"),t(258,"Position-wise Feed-Forward Network:"),e(),t(259," Same as in the encoder"),e()(),n(260,"h3"),t(261,"Modern Variants"),e(),n(262,"p"),t(263,"Many modern NLP models use modified transformer architectures:"),e(),n(264,"ul")(265,"li")(266,"strong"),t(267,"BERT:"),e(),t(268," Uses only the encoder stack for bidirectional understanding"),e(),n(269,"li")(270,"strong"),t(271,"GPT:"),e(),t(272," Uses only the decoder stack for unidirectional text generation"),e(),n(273,"li")(274,"strong"),t(275,"T5:"),e(),t(276," Uses the full encoder-decoder structure with unified text-to-text approach"),e()()()(),n(277,"div",27)(278,"h2"),t(279,"Self-Attention Mechanism"),e(),n(280,"div",28)(281,"div",75)(282,"div",76)(283,"h3"),t(284,"Scaled Dot-Product Attention"),e(),n(285,"p"),t(286,"Self-attention computes a representation for each element by attending to all elements in the sequence and taking their weighted average."),e(),n(287,"div",77)(288,"span",78),t(289,"Attention(Q, K, V) = softmax(QK"),n(290,"sup"),t(291,"T"),e(),t(292,"/\u221Ad"),n(293,"sub"),t(294,"k"),e(),t(295,")V"),e()(),n(296,"h4"),t(297,"Components:"),e(),n(298,"ul")(299,"li")(300,"strong"),t(301,"Queries (Q):"),e(),t(302,' Represents the element "asking" for relevant information'),e(),n(303,"li")(304,"strong"),t(305,"Keys (K):"),e(),t(306,' Represents what information each element "offers"'),e(),n(307,"li")(308,"strong"),t(309,"Values (V):"),e(),t(310," Represents the actual content of each element"),e()(),n(311,"h4"),t(312,"Process:"),e(),n(313,"ol")(314,"li"),t(315,"Compute compatibility between queries and keys"),e(),n(316,"li"),t(317,"Scale dot products by \u221Ad"),n(318,"sub"),t(319,"k"),e(),t(320," to stabilize gradients"),e(),n(321,"li"),t(322,"Apply softmax to get attention weights"),e(),n(323,"li"),t(324,"Take weighted sum of value vectors"),e()(),n(325,"h3"),t(326,"Multi-Head Attention"),e(),n(327,"p"),t(328,"Instead of performing a single attention operation, the transformer uses multiple attention heads in parallel:"),e(),n(329,"ul")(330,"li"),t(331,"Each head can focus on different aspects of the relationship between tokens"),e(),n(332,"li"),t(333,"Enables the model to jointly attend to different representation subspaces"),e(),n(334,"li"),t(335,"Outputs are concatenated and projected to obtain final values"),e()(),n(336,"div",77)(337,"span",78),t(338,"MultiHead(Q,K,V) = Concat(head"),n(339,"sub"),t(340,"1"),e(),t(341,",...,head"),n(342,"sub"),t(343,"h"),e(),t(344,")W"),n(345,"sup"),t(346,"O"),e()()()(),x(347,"div",79,1),e()()(),n(349,"div",27)(350,"h2"),t(351,"Positional Encoding"),e(),n(352,"div",28)(353,"div",80)(354,"div",81)(355,"h3"),t(356,"Purpose"),e(),n(357,"p"),t(358,"Since self-attention treats inputs as a set of vectors with no inherent order, positional information must be explicitly added to the token embeddings."),e(),n(359,"h3"),t(360,"Sine-Cosine Encoding"),e(),n(361,"p"),t(362,"The original transformer uses a fixed encoding pattern based on sine and cosine functions:"),e(),n(363,"div",77)(364,"div",78),t(365,"PE"),n(366,"sub"),t(367,"(pos,2i)"),e(),t(368," = sin(pos/10000"),n(369,"sup"),t(370,"2i/d"),n(371,"sub"),t(372,"model"),e()(),t(373,")"),e(),n(374,"div",78),t(375,"PE"),n(376,"sub"),t(377,"(pos,2i+1)"),e(),t(378," = cos(pos/10000"),n(379,"sup"),t(380,"2i/d"),n(381,"sub"),t(382,"model"),e()(),t(383,")"),e()(),n(384,"h4"),t(385,"Properties:"),e(),n(386,"ul")(387,"li"),t(388,"Unique encoding for each position up to a very large sequence length"),e(),n(389,"li"),t(390,"Deterministic, allowing extrapolation to unseen sequence lengths"),e(),n(391,"li"),t(392,"Enables the model to attend to relative positions through linear combinations"),e(),n(393,"li"),t(394,"Each dimension corresponds to a different wavelength from 2\u03C0 to 10000\xB72\u03C0"),e()(),n(395,"h3"),t(396,"Alternatives"),e(),n(397,"p"),t(398,"Modern transformers may use other positional encoding approaches:"),e(),n(399,"ul")(400,"li")(401,"strong"),t(402,"Learned positional embeddings:"),e(),t(403," Trainable parameters rather than fixed functions"),e(),n(404,"li")(405,"strong"),t(406,"Relative positional encodings:"),e(),t(407," Encode relative rather than absolute positions"),e(),n(408,"li")(409,"strong"),t(410,"Rotary positional embeddings (RoPE):"),e(),t(411," Apply rotation to embedding vectors"),e()()(),x(412,"div",82,2),e()()(),n(414,"div",27)(415,"h2"),t(416,"Research Papers"),e(),n(417,"div",28)(418,"p",83),t(419,"The transformer architecture has sparked a revolution in NLP and beyond. Here are key research papers that have defined the field:"),e(),n(420,"div",84),q(421,Jt,12,6,"div",85),e(),n(422,"div",86)(423,"h3"),t(424,"Citing the Original Paper"),e(),n(425,"div",87)(426,"div",88)(427,"h4"),t(428,"APA"),e(),n(429,"p",89),t(430,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008)."),e()(),n(431,"div",88)(432,"h4"),t(433,"BibTeX"),e(),n(434,"pre",89),t(435,`@inproceedings{vaswani2017attention,
    title={Attention is all you need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and 
      Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and 
      Kaiser, {\\L}ukasz and Polosukhin, Illia},
    booktitle={Advances in neural information processing systems},
    pages={5998--6008},
    year={2017}
  }`),e()()()()()(),n(436,"div",27)(437,"h2"),t(438,"Applications"),e(),n(439,"div",28)(440,"div",90)(441,"div",91)(442,"div",92),t(443,"\u{1F524}"),e(),n(444,"h3"),t(445,"Natural Language Processing"),e(),n(446,"ul")(447,"li")(448,"strong"),t(449,"Machine Translation:"),e(),t(450," Models like Google's Transformer achieve state-of-the-art results in language translation tasks."),e(),n(451,"li")(452,"strong"),t(453,"Text Summarization:"),e(),t(454," Transformers can generate concise summaries while preserving meaning."),e(),n(455,"li")(456,"strong"),t(457,"Question Answering:"),e(),t(458," Models can understand questions and extract relevant answers from context."),e(),n(459,"li")(460,"strong"),t(461,"Text Generation:"),e(),t(462," GPT models generate remarkably coherent and contextually relevant text."),e()()(),n(463,"div",91)(464,"div",92),t(465,"\u{1F5BC}\uFE0F"),e(),n(466,"h3"),t(467,"Computer Vision"),e(),n(468,"ul")(469,"li")(470,"strong"),t(471,"Image Classification:"),e(),t(472," Vision Transformers (ViT) approach or exceed CNN performance."),e(),n(473,"li")(474,"strong"),t(475,"Object Detection:"),e(),t(476," DETR (DEtection TRansformer) simplifies the detection pipeline."),e(),n(477,"li")(478,"strong"),t(479,"Image Generation:"),e(),t(480," Transformers are being used in models like DALL-E for text-to-image generation."),e(),n(481,"li")(482,"strong"),t(483,"Video Understanding:"),e(),t(484," Processing sequence of frames for action recognition and prediction."),e()()(),n(485,"div",91)(486,"div",92),t(487,"\u{1F9EC}"),e(),n(488,"h3"),t(489,"Bioinformatics"),e(),n(490,"ul")(491,"li")(492,"strong"),t(493,"Protein Structure Prediction:"),e(),t(494," AlphaFold 2 uses attention mechanisms for breakthrough results."),e(),n(495,"li")(496,"strong"),t(497,"Genomic Sequence Analysis:"),e(),t(498," Modeling DNA/RNA sequences and their interactions."),e(),n(499,"li")(500,"strong"),t(501,"Drug Discovery:"),e(),t(502," Predicting molecular properties and drug-target interactions."),e()()(),n(503,"div",91)(504,"div",92),t(505,"\u{1F50A}"),e(),n(506,"h3"),t(507,"Audio Processing"),e(),n(508,"ul")(509,"li")(510,"strong"),t(511,"Speech Recognition:"),e(),t(512," Transformers achieve high accuracy in converting speech to text."),e(),n(513,"li")(514,"strong"),t(515,"Voice Synthesis:"),e(),t(516," Generating realistic human-like speech."),e(),n(517,"li")(518,"strong"),t(519,"Music Generation:"),e(),t(520," Creating new musical compositions in specific styles."),e(),n(521,"li")(522,"strong"),t(523,"Audio Classification:"),e(),t(524," Identifying sounds, music genres, and environmental audio."),e()()(),n(525,"div",91)(526,"div",92),t(527,"\u{1F3AE}"),e(),n(528,"h3"),t(529,"Reinforcement Learning"),e(),n(530,"ul")(531,"li")(532,"strong"),t(533,"Decision Transformer:"),e(),t(534," Framing RL as a sequence modeling problem."),e(),n(535,"li")(536,"strong"),t(537,"Game Playing:"),e(),t(538," Models that understand game states and choose optimal actions."),e(),n(539,"li")(540,"strong"),t(541,"Robotics:"),e(),t(542," Controlling robot actions based on sensory input sequences."),e()()(),n(543,"div",91)(544,"div",92),t(545,"\u{1F4CA}"),e(),n(546,"h3"),t(547,"Time Series Analysis"),e(),n(548,"ul")(549,"li")(550,"strong"),t(551,"Forecasting:"),e(),t(552," Predicting future values based on historical data sequences."),e(),n(553,"li")(554,"strong"),t(555,"Anomaly Detection:"),e(),t(556," Identifying unusual patterns in sequential data."),e(),n(557,"li")(558,"strong"),t(559,"Financial Modeling:"),e(),t(560," Stock price prediction and market trend analysis."),e(),n(561,"li")(562,"strong"),t(563,"Weather Prediction:"),e(),t(564," Modeling complex atmospheric patterns over time."),e()()()(),n(565,"div",93)(566,"h3"),t(567,"Future Directions"),e(),n(568,"p"),t(569,"Transformer models continue to evolve in capabilities and efficiency:"),e(),n(570,"ul")(571,"li")(572,"strong"),t(573,"Multimodal Transformers:"),e(),t(574," Processing and generating content across text, images, audio, and video"),e(),n(575,"li")(576,"strong"),t(577,"Efficient Transformers:"),e(),t(578," Addressing the quadratic complexity issue for very long sequences"),e(),n(579,"li")(580,"strong"),t(581,"Domain-Specific Architectures:"),e(),t(582," Specialized transformer variants for particular applications"),e(),n(583,"li")(584,"strong"),t(585,"Smaller, Distilled Models:"),e(),t(586," Making transformers accessible for edge devices and real-time applications"),e()()()()()()()}a&2&&(d(8),R("active",o.activeSection==="overview"),d(5),R("active",o.activeSection==="architecture"),d(5),R("active",o.activeSection==="attention"),d(5),R("active",o.activeSection==="positional"),d(5),R("active",o.activeSection==="research"),d(5),R("active",o.activeSection==="applications"),d(15),R("playing",o.isPlaying),d(),f("ngSwitch",o.isPlaying),d(),f("ngSwitchCase",!1),d(),f("ngSwitchCase",!0),d(6),pt("width",o.currentStep/(o.totalSteps-1)*100,"%"),d(2),X(" Step ",o.currentStep+1," of ",o.totalSteps," "),d(2),R("fullscreen",o.activeSection==="architecture"),d(4),f("ngSwitch",o.currentStep),d(),f("ngSwitchCase",0),d(),f("ngSwitchCase",1),d(),f("ngSwitchCase",2),d(),f("ngSwitchCase",3),d(),f("ngSwitchCase",4),d(),f("ngSwitchCase",5),d(),f("ngSwitchCase",6),d(),f("ngSwitchCase",7),d(),f("hidden",o.activeSection!=="overview"),d(77),f("hidden",o.activeSection!=="architecture"),d(126),f("hidden",o.activeSection!=="attention"),d(72),f("hidden",o.activeSection!=="positional"),d(65),f("hidden",o.activeSection!=="research"),d(7),f("ngForOf",o.researchPapers),d(15),f("hidden",o.activeSection!=="applications"))},dependencies:[gt,ft,xt,ut],styles:['@charset "UTF-8";*[_ngcontent-%COMP%]{box-sizing:border-box;margin:0;padding:0}body[_ngcontent-%COMP%]{font-family:Inter,Roboto,sans-serif;color:#e1e7f5;background-color:#0c1428;line-height:1.5}.transformer-container[_ngcontent-%COMP%]{display:flex;width:100%;height:100vh;overflow:hidden;background-color:#0c1428}.sidebar[_ngcontent-%COMP%]{width:280px;height:100%;background-color:#162a4a;border-right:1px solid rgba(139,180,250,.1);padding:16px;display:flex;flex-direction:column;z-index:10;box-shadow:2px 0 10px #0003;overflow-y:auto}.logo[_ngcontent-%COMP%]{padding:16px 0 32px;border-bottom:1px solid rgba(139,180,250,.1);margin-bottom:24px}.logo[_ngcontent-%COMP%]   h2[_ngcontent-%COMP%]{color:#fff;font-size:24px;font-weight:700;margin-bottom:4px}.logo[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#4285f4;font-size:14px;font-weight:500}.nav-list[_ngcontent-%COMP%]{list-style:none;margin-bottom:32px}.nav-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{display:flex;align-items:center;padding:16px;border-radius:8px;margin-bottom:4px;cursor:pointer;transition:background-color .3s ease-in-out}.nav-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]:hover{background-color:#2a498066}.nav-list[_ngcontent-%COMP%]   li.active[_ngcontent-%COMP%]{background-color:#2a4980;position:relative}.nav-list[_ngcontent-%COMP%]   li.active[_ngcontent-%COMP%]:before{content:"";position:absolute;left:0;top:0;bottom:0;width:4px;background:linear-gradient(135deg,#4285f4,#7c4dff);border-radius:0 4px 4px 0}.nav-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   .icon[_ngcontent-%COMP%]{margin-right:16px;font-size:18px}.nav-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   .text[_ngcontent-%COMP%]{font-size:14px;font-weight:500}.sim-controls[_ngcontent-%COMP%]{margin-top:auto;padding-top:24px;border-top:1px solid rgba(139,180,250,.1)}.sim-controls[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{font-size:16px;font-weight:600;margin-bottom:16px;color:#fff}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]{display:flex;justify-content:space-between;margin-bottom:16px}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn[_ngcontent-%COMP%]{background-color:#1e3a66;border:none;color:#e1e7f5;width:40px;height:40px;border-radius:50%;display:flex;align-items:center;justify-content:center;cursor:pointer;transition:all .3s ease-in-out}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn[_ngcontent-%COMP%]:hover{background-color:#2a4980}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn.play-btn[_ngcontent-%COMP%]{width:50px;height:50px;background-color:#4285f4}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn.play-btn[_ngcontent-%COMP%]:hover{background-color:#2c5cbd}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn.play-btn.playing[_ngcontent-%COMP%]{background-color:#ff9d45}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn.play-btn.playing[_ngcontent-%COMP%]:hover{background-color:#ff8212}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn[_ngcontent-%COMP%]   .icon[_ngcontent-%COMP%]{font-size:18px}.sim-controls[_ngcontent-%COMP%]   .step-indicator[_ngcontent-%COMP%]{margin-top:16px}.sim-controls[_ngcontent-%COMP%]   .step-indicator[_ngcontent-%COMP%]   .step-progress[_ngcontent-%COMP%]{height:6px;background-color:#1e3a66;border-radius:4px;margin-bottom:4px;overflow:hidden}.sim-controls[_ngcontent-%COMP%]   .step-indicator[_ngcontent-%COMP%]   .step-progress[_ngcontent-%COMP%]   .progress-bar[_ngcontent-%COMP%]{height:100%;background:linear-gradient(135deg,#4285f4,#7c4dff);border-radius:4px;transition:width .3s ease-in-out}.sim-controls[_ngcontent-%COMP%]   .step-indicator[_ngcontent-%COMP%]   .step-text[_ngcontent-%COMP%]{font-size:12px;color:#8a9ab0;text-align:center}.content-area[_ngcontent-%COMP%]{flex:1;height:100%;overflow-y:auto;display:flex;flex-direction:column}.visualization-area[_ngcontent-%COMP%]{position:relative;height:50vh;min-height:400px;background-color:#0c1428;overflow:hidden;transition:height .3s ease-in-out}.visualization-area.fullscreen[_ngcontent-%COMP%]{height:70vh}.visualization-area[_ngcontent-%COMP%]   .three-canvas[_ngcontent-%COMP%]{width:100%;height:100%}.visualization-area[_ngcontent-%COMP%]   .step-description[_ngcontent-%COMP%]{position:absolute;bottom:0;left:0;right:0;background:linear-gradient(to top,rgba(12,20,40,.9),rgba(12,20,40,.6),transparent);padding:16px 32px}.visualization-area[_ngcontent-%COMP%]   .step-description[_ngcontent-%COMP%]   .step-content[_ngcontent-%COMP%]{max-width:600px;margin:0 auto}.visualization-area[_ngcontent-%COMP%]   .step-description[_ngcontent-%COMP%]   .step-content[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{color:#fff;font-size:20px;font-weight:600;margin-bottom:8px}.visualization-area[_ngcontent-%COMP%]   .step-description[_ngcontent-%COMP%]   .step-content[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#e1e7f5;font-size:15px;line-height:1.6}.info-section[_ngcontent-%COMP%]{flex:1;padding:32px;background-color:#162a4a;overflow-y:auto}.info-section[_ngcontent-%COMP%]   h2[_ngcontent-%COMP%]{color:#fff;font-size:28px;font-weight:700;margin-bottom:24px;position:relative;display:inline-block}.info-section[_ngcontent-%COMP%]   h2[_ngcontent-%COMP%]:after{content:"";position:absolute;bottom:-4px;left:0;width:60%;height:3px;background:linear-gradient(135deg,#4285f4,#7c4dff);border-radius:4px}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]{max-width:1200px;margin:0 auto}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{color:#fff;font-size:22px;font-weight:600;margin:24px 0 16px}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   h4[_ngcontent-%COMP%]{color:#6edfff;font-size:18px;font-weight:600;margin:16px 0 8px}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#e1e7f5;font-size:16px;line-height:1.6;margin-bottom:16px}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]   strong[_ngcontent-%COMP%]{color:#fff}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%], .info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   ol[_ngcontent-%COMP%]{margin-left:32px;margin-bottom:24px}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%], .info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   ol[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{color:#e1e7f5;font-size:16px;margin-bottom:8px}.info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   strong[_ngcontent-%COMP%], .info-section[_ngcontent-%COMP%]   .info-content[_ngcontent-%COMP%]   ol[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   strong[_ngcontent-%COMP%]{color:#fff}.application-cards[_ngcontent-%COMP%]{display:flex;flex-wrap:wrap;gap:16px;margin:24px 0}.application-cards[_ngcontent-%COMP%]   .app-card[_ngcontent-%COMP%]{flex:1 1 200px;background-color:#1e3a66;border-radius:12px;padding:24px;box-shadow:0 4px 8px #0003;transition:transform .3s ease-in-out}.application-cards[_ngcontent-%COMP%]   .app-card[_ngcontent-%COMP%]:hover{transform:translateY(-5px)}.application-cards[_ngcontent-%COMP%]   .app-card[_ngcontent-%COMP%]   .app-icon[_ngcontent-%COMP%]{font-size:32px;margin-bottom:16px;text-align:center}.application-cards[_ngcontent-%COMP%]   .app-card[_ngcontent-%COMP%]   .app-icon.large[_ngcontent-%COMP%]{font-size:48px}.application-cards[_ngcontent-%COMP%]   .app-card[_ngcontent-%COMP%]   h4[_ngcontent-%COMP%]{color:#fff;font-size:18px;font-weight:600;margin-bottom:8px}.application-cards[_ngcontent-%COMP%]   .app-card[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#e1e7f5;font-size:14px;margin-bottom:0}.benefits-list[_ngcontent-%COMP%]{list-style:none;margin-left:0!important}.benefits-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{position:relative;padding-left:32px;margin-bottom:16px!important}.benefits-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]:before{content:"\\2713";position:absolute;left:0;color:#24b47e;font-weight:700}.architecture-diagram[_ngcontent-%COMP%]{text-align:center;margin:32px 0}.architecture-diagram[_ngcontent-%COMP%]   img[_ngcontent-%COMP%]{max-width:100%;height:auto;border-radius:8px;box-shadow:0 4px 16px #0000004d}.attention-container[_ngcontent-%COMP%]{display:flex;flex-wrap:wrap;gap:32px}.attention-container[_ngcontent-%COMP%]   .attention-text[_ngcontent-%COMP%]{flex:1;min-width:300px}.attention-container[_ngcontent-%COMP%]   .attention-vis-container[_ngcontent-%COMP%]{flex:1;min-width:400px;min-height:400px;background-color:#0c1428;border-radius:12px;overflow:hidden}.positional-container[_ngcontent-%COMP%]{display:flex;flex-wrap:wrap;gap:32px}.positional-container[_ngcontent-%COMP%]   .positional-text[_ngcontent-%COMP%]{flex:1;min-width:300px}.positional-container[_ngcontent-%COMP%]   .positional-vis-container[_ngcontent-%COMP%]{flex:1;min-width:400px;min-height:400px;background-color:#0c1428;border-radius:12px;overflow:hidden}.equation[_ngcontent-%COMP%]{background-color:#1e3a6680;border-radius:8px;padding:16px;margin:16px 0;overflow-x:auto}.equation[_ngcontent-%COMP%]   .formula[_ngcontent-%COMP%]{display:block;text-align:center;font-family:"CMU Serif",serif;color:#fff;font-size:18px;line-height:1.8}.papers-container[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(300px,1fr));gap:24px;margin:32px 0}.paper-card[_ngcontent-%COMP%]{background-color:#1e3a66;border-radius:12px;padding:24px;box-shadow:0 4px 8px #0003;transition:transform .3s ease-in-out}.paper-card[_ngcontent-%COMP%]:hover{transform:translateY(-5px)}.paper-card[_ngcontent-%COMP%]   .paper-title[_ngcontent-%COMP%]{color:#fff;font-size:18px;font-weight:700;margin-bottom:8px}.paper-card[_ngcontent-%COMP%]   .paper-authors[_ngcontent-%COMP%]{color:#8a9ab0;font-size:14px;margin-bottom:8px}.paper-card[_ngcontent-%COMP%]   .paper-publication[_ngcontent-%COMP%]{color:#ae94ff;font-size:14px;font-weight:500;margin-bottom:16px}.paper-card[_ngcontent-%COMP%]   .paper-description[_ngcontent-%COMP%]{color:#e1e7f5;font-size:14px;margin-bottom:16px}.paper-card[_ngcontent-%COMP%]   .paper-link[_ngcontent-%COMP%]   a[_ngcontent-%COMP%]{display:inline-block;padding:8px 16px;background-color:#8bb4fa33;color:#8bb4fa;text-decoration:none;border-radius:4px;font-size:14px;font-weight:500;transition:all .3s ease-in-out}.paper-card[_ngcontent-%COMP%]   .paper-link[_ngcontent-%COMP%]   a[_ngcontent-%COMP%]:hover{background-color:#8bb4fa4d}.citation-info[_ngcontent-%COMP%]{margin-top:32px;padding-top:24px;border-top:1px solid rgba(139,180,250,.1)}.citation-info[_ngcontent-%COMP%]   .citation-formats[_ngcontent-%COMP%]{display:flex;flex-wrap:wrap;gap:24px;margin-top:16px}.citation-info[_ngcontent-%COMP%]   .citation-formats[_ngcontent-%COMP%]   .citation-format[_ngcontent-%COMP%]{flex:1;min-width:300px}.citation-info[_ngcontent-%COMP%]   .citation-formats[_ngcontent-%COMP%]   .citation-format[_ngcontent-%COMP%]   h4[_ngcontent-%COMP%]{color:#fff;margin-bottom:8px}.citation-info[_ngcontent-%COMP%]   .citation-formats[_ngcontent-%COMP%]   .citation-format[_ngcontent-%COMP%]   .citation-text[_ngcontent-%COMP%]{background-color:#0c1428;padding:16px;border-radius:4px;font-size:14px;line-height:1.5;overflow-x:auto}.citation-info[_ngcontent-%COMP%]   .citation-formats[_ngcontent-%COMP%]   .citation-format[_ngcontent-%COMP%]   pre.citation-text[_ngcontent-%COMP%]{font-family:Courier New,monospace;white-space:pre-wrap}.applications-grid[_ngcontent-%COMP%]{display:grid;grid-template-columns:repeat(auto-fill,minmax(350px,1fr));gap:32px;margin-bottom:32px}.application-block[_ngcontent-%COMP%]{background-color:#1e3a66;border-radius:12px;padding:24px;box-shadow:0 4px 8px #0003}.application-block[_ngcontent-%COMP%]   .app-icon[_ngcontent-%COMP%]{font-size:32px;margin-bottom:16px;text-align:center}.application-block[_ngcontent-%COMP%]   .app-icon.large[_ngcontent-%COMP%]{font-size:48px}.application-block[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{color:#fff;font-size:20px;font-weight:700;margin-bottom:16px;text-align:center}.application-block[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]{margin-left:24px!important}.application-block[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{margin-bottom:8px!important}.application-block[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   strong[_ngcontent-%COMP%]{color:#fff}.future-applications[_ngcontent-%COMP%]{background-color:#7c4dff1a;border-radius:12px;padding:24px;margin-top:32px;border-left:4px solid #7c4dff}.future-applications[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{color:#ae94ff!important}@media (max-width: 1024px){.sidebar[_ngcontent-%COMP%]{width:240px}}@media (max-width: 768px){.transformer-container[_ngcontent-%COMP%]{flex-direction:column}.sidebar[_ngcontent-%COMP%]{width:100%;height:auto;border-right:none;border-bottom:1px solid rgba(139,180,250,.1);padding:8px}.logo[_ngcontent-%COMP%]{padding:8px 0;margin-bottom:8px}.nav-list[_ngcontent-%COMP%]{display:flex;flex-wrap:wrap;margin-bottom:16px}.nav-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{padding:8px;margin-right:4px;margin-bottom:4px}.nav-list[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   .icon[_ngcontent-%COMP%]{margin-right:8px}.sim-controls[_ngcontent-%COMP%]{padding-top:8px}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn[_ngcontent-%COMP%]{width:36px;height:36px}.sim-controls[_ngcontent-%COMP%]   .control-buttons[_ngcontent-%COMP%]   .btn.play-btn[_ngcontent-%COMP%]{width:44px;height:44px}.visualization-area[_ngcontent-%COMP%]{height:40vh;min-height:300px}.visualization-area.fullscreen[_ngcontent-%COMP%]{height:50vh}.attention-container[_ngcontent-%COMP%], .positional-container[_ngcontent-%COMP%]{flex-direction:column}.attention-container[_ngcontent-%COMP%]   .attention-vis-container[_ngcontent-%COMP%], .attention-container[_ngcontent-%COMP%]   .positional-vis-container[_ngcontent-%COMP%], .positional-container[_ngcontent-%COMP%]   .attention-vis-container[_ngcontent-%COMP%], .positional-container[_ngcontent-%COMP%]   .positional-vis-container[_ngcontent-%COMP%]{min-height:300px}}@keyframes _ngcontent-%COMP%_pulse{0%{opacity:1}50%{opacity:.6}to{opacity:1}}@keyframes _ngcontent-%COMP%_fade-in{0%{opacity:0}to{opacity:1}}@keyframes _ngcontent-%COMP%_slide-in{0%{transform:translateY(20px);opacity:0}to{transform:translateY(0);opacity:1}}.info-content[_ngcontent-%COMP%]{animation:_ngcontent-%COMP%_fade-in .5s ease-out}.step-content[_ngcontent-%COMP%]{animation:_ngcontent-%COMP%_slide-in .3s ease-out}[_ngcontent-%COMP%]::-webkit-scrollbar{width:8px;height:8px}[_ngcontent-%COMP%]::-webkit-scrollbar-track{background:#0c1428}[_ngcontent-%COMP%]::-webkit-scrollbar-thumb{background:#1e3a66;border-radius:4px}[_ngcontent-%COMP%]::-webkit-scrollbar-thumb:hover{background:#2a4980}']})};export{Dt as TransformerNetworkComponent};
